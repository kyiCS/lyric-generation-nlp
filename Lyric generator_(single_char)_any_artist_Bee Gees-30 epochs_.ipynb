{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Artificial lyric generator_(single_char)_any_artist_\n",
    "- Use recurrent neural network\n",
    "- Mimic any popular artists from datasets\n",
    "- use single characters as sequential inputs\n",
    "- Bee Gees as example\n",
    "#### Dawson Sargent, Chenghui Song, Kelvin Yi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create songlist from the datasets\n",
    "Data source: https://www.kaggle.com/datasets/neisse/scrapped-lyrics-from-6-genres?select=lyrics-data.csv\n",
    "- Two csv datasets are needed:\n",
    " - lyrics-data.csv: \n",
    " - artists-data.csv: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of songlist from popular artists: (12330, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Artist</th>\n",
       "      <th>Genres</th>\n",
       "      <th>Popularity</th>\n",
       "      <th>Songs</th>\n",
       "      <th>SName</th>\n",
       "      <th>Lyric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>120727</th>\n",
       "      <td>Frank Sinatra</td>\n",
       "      <td>Jazz; Clássico; Romântico</td>\n",
       "      <td>16.1</td>\n",
       "      <td>828.0</td>\n",
       "      <td>My Way</td>\n",
       "      <td>And now the end is near,\\nAnd so I face the fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120728</th>\n",
       "      <td>Frank Sinatra</td>\n",
       "      <td>Jazz; Clássico; Romântico</td>\n",
       "      <td>16.1</td>\n",
       "      <td>828.0</td>\n",
       "      <td>Fly Me to the Moon</td>\n",
       "      <td>Fly me to the moon\\nLet me play among the star...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120729</th>\n",
       "      <td>Frank Sinatra</td>\n",
       "      <td>Jazz; Clássico; Romântico</td>\n",
       "      <td>16.1</td>\n",
       "      <td>828.0</td>\n",
       "      <td>New York, New York</td>\n",
       "      <td>Start spreading the news,\\nI'm leaving today\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120730</th>\n",
       "      <td>Frank Sinatra</td>\n",
       "      <td>Jazz; Clássico; Romântico</td>\n",
       "      <td>16.1</td>\n",
       "      <td>828.0</td>\n",
       "      <td>That's Life</td>\n",
       "      <td>That's life, that's what all the people say.\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120731</th>\n",
       "      <td>Frank Sinatra</td>\n",
       "      <td>Jazz; Clássico; Romântico</td>\n",
       "      <td>16.1</td>\n",
       "      <td>828.0</td>\n",
       "      <td>Days Of Wine and Roses</td>\n",
       "      <td>&lt;with a jauntier melody than Andy Williams' ve...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Artist                     Genres  Popularity  Songs  \\\n",
       "120727  Frank Sinatra  Jazz; Clássico; Romântico        16.1  828.0   \n",
       "120728  Frank Sinatra  Jazz; Clássico; Romântico        16.1  828.0   \n",
       "120729  Frank Sinatra  Jazz; Clássico; Romântico        16.1  828.0   \n",
       "120730  Frank Sinatra  Jazz; Clássico; Romântico        16.1  828.0   \n",
       "120731  Frank Sinatra  Jazz; Clássico; Romântico        16.1  828.0   \n",
       "\n",
       "                         SName  \\\n",
       "120727                  My Way   \n",
       "120728      Fly Me to the Moon   \n",
       "120729      New York, New York   \n",
       "120730             That's Life   \n",
       "120731  Days Of Wine and Roses   \n",
       "\n",
       "                                                    Lyric  \n",
       "120727  And now the end is near,\\nAnd so I face the fi...  \n",
       "120728  Fly me to the moon\\nLet me play among the star...  \n",
       "120729  Start spreading the news,\\nI'm leaving today\\n...  \n",
       "120730  That's life, that's what all the people say.\\n...  \n",
       "120731  <with a jauntier melody than Andy Williams' ve...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#curr_dir = 'C:\\\\Users\\\\cheng\\\\Downloads\\\\'\n",
    "lyrics = pd.read_csv('lyrics-data.csv') \n",
    "lyrics=lyrics.query(\"language=='en'\")\n",
    "artists = pd.read_csv(\"artists-data.csv\")\n",
    "lyrics_df = pd.merge(lyrics,artists,left_on=\"ALink\",right_on=\"Link\")\n",
    "lyrics_df = lyrics_df[[\"Artist\",\"Genres\",\"Popularity\",\"Songs\",\"SName\",\"Lyric\"]]\n",
    "        # Note: Popularity score based on how much each artist/lyric is accessed on the website\n",
    "lyrics_popular=lyrics_df.query(\"Songs>500\")\n",
    "lyrics_popular=lyrics_popular.sort_values(['Songs','Artist'], ascending=[False,True])\n",
    "#lyrics_hop = lyrics_df[lyrics_df[\"Genres\"].str.contains(\"Hip Hop\",na=False)]\n",
    "print(\"Shape of songlist from popular artists:\",lyrics_popular.shape)\n",
    "lyrics_popular.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the most popular artists by number of songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Artist</th>\n",
       "      <th>Genres</th>\n",
       "      <th>Popularity</th>\n",
       "      <th>Songs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Frank Sinatra</td>\n",
       "      <td>Jazz; Clássico; Romântico</td>\n",
       "      <td>16.1</td>\n",
       "      <td>819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Elvis Presley</td>\n",
       "      <td>Rockabilly; Romântico; Rock</td>\n",
       "      <td>23.1</td>\n",
       "      <td>747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dolly Parton</td>\n",
       "      <td>Country</td>\n",
       "      <td>1.3</td>\n",
       "      <td>723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Matheus Hardke</td>\n",
       "      <td>Pop/Rock</td>\n",
       "      <td>0.1</td>\n",
       "      <td>707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lil Wayne</td>\n",
       "      <td>R&amp;B; Black Music; Rap</td>\n",
       "      <td>4.3</td>\n",
       "      <td>689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Glee</td>\n",
       "      <td>Trilha Sonora; Pop/Rock; Pop</td>\n",
       "      <td>3.0</td>\n",
       "      <td>687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Hillsong United</td>\n",
       "      <td>Gospel/Religioso; Pop/Rock; Rock</td>\n",
       "      <td>25.8</td>\n",
       "      <td>646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Elton John</td>\n",
       "      <td>Soft Rock; Romântico; Pop/Rock</td>\n",
       "      <td>44.7</td>\n",
       "      <td>638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Temas de Filmes</td>\n",
       "      <td>COLETÂNEA; Trilha Sonora; Romântico; Instrumental</td>\n",
       "      <td>8.3</td>\n",
       "      <td>628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Chris Brown</td>\n",
       "      <td>Rap; Hip Hop; Pop</td>\n",
       "      <td>11.8</td>\n",
       "      <td>623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Guided By Voices</td>\n",
       "      <td>Indie</td>\n",
       "      <td>0.0</td>\n",
       "      <td>620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Prince</td>\n",
       "      <td>R&amp;B; Black Music; Funk</td>\n",
       "      <td>2.8</td>\n",
       "      <td>564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Johnny Cash</td>\n",
       "      <td>Folk; Country; Rock</td>\n",
       "      <td>14.1</td>\n",
       "      <td>555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Bee Gees</td>\n",
       "      <td>Soft Rock; Disco; Pop</td>\n",
       "      <td>18.0</td>\n",
       "      <td>550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Bob Dylan</td>\n",
       "      <td>Folk; Rock; Country</td>\n",
       "      <td>6.9</td>\n",
       "      <td>548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>George Jones</td>\n",
       "      <td>Country; Folk</td>\n",
       "      <td>0.0</td>\n",
       "      <td>534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Elvis Costello</td>\n",
       "      <td>Pop/Rock; Rock; New Wave</td>\n",
       "      <td>1.0</td>\n",
       "      <td>522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Neil Young</td>\n",
       "      <td>Rock; Folk</td>\n",
       "      <td>2.6</td>\n",
       "      <td>515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Bruce Springsteen</td>\n",
       "      <td>Rock</td>\n",
       "      <td>5.2</td>\n",
       "      <td>502</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Artist                                             Genres  \\\n",
       "0       Frank Sinatra                          Jazz; Clássico; Romântico   \n",
       "1       Elvis Presley                        Rockabilly; Romântico; Rock   \n",
       "2        Dolly Parton                                            Country   \n",
       "3      Matheus Hardke                                           Pop/Rock   \n",
       "4           Lil Wayne                              R&B; Black Music; Rap   \n",
       "5                Glee                       Trilha Sonora; Pop/Rock; Pop   \n",
       "6     Hillsong United                   Gospel/Religioso; Pop/Rock; Rock   \n",
       "7          Elton John                     Soft Rock; Romântico; Pop/Rock   \n",
       "8     Temas de Filmes  COLETÂNEA; Trilha Sonora; Romântico; Instrumental   \n",
       "9         Chris Brown                                  Rap; Hip Hop; Pop   \n",
       "10   Guided By Voices                                              Indie   \n",
       "11             Prince                             R&B; Black Music; Funk   \n",
       "12        Johnny Cash                                Folk; Country; Rock   \n",
       "13           Bee Gees                              Soft Rock; Disco; Pop   \n",
       "14          Bob Dylan                                Folk; Rock; Country   \n",
       "15       George Jones                                      Country; Folk   \n",
       "16     Elvis Costello                           Pop/Rock; Rock; New Wave   \n",
       "17         Neil Young                                         Rock; Folk   \n",
       "18  Bruce Springsteen                                               Rock   \n",
       "\n",
       "    Popularity  Songs  \n",
       "0         16.1    819  \n",
       "1         23.1    747  \n",
       "2          1.3    723  \n",
       "3          0.1    707  \n",
       "4          4.3    689  \n",
       "5          3.0    687  \n",
       "6         25.8    646  \n",
       "7         44.7    638  \n",
       "8          8.3    628  \n",
       "9         11.8    623  \n",
       "10         0.0    620  \n",
       "11         2.8    564  \n",
       "12        14.1    555  \n",
       "13        18.0    550  \n",
       "14         6.9    548  \n",
       "15         0.0    534  \n",
       "16         1.0    522  \n",
       "17         2.6    515  \n",
       "18         5.2    502  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find list of artists that have > 500 songs in the current dataset\n",
    "artists = lyrics_popular.reset_index()\n",
    "artists = artists.drop(columns=['index'])\n",
    "artists = artists[[\"Artist\",\"Genres\",\"Popularity\",\"Songs\",'SName']]\n",
    "artists_songs = artists.groupby(['Artist','Genres','Popularity','Songs'])[\"SName\"].count()\n",
    "list = artists_songs.reset_index()\n",
    "list=list.drop(columns=['Songs'])\n",
    "list=list.rename(columns={'SName':'Songs'})\n",
    "list=list.query(\"Songs>500\")\n",
    "list=list.reset_index().drop(columns=['index'])\n",
    "list = list.sort_values(['Songs'],ascending=False).reset_index().drop(columns=['index'])\n",
    "list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select an artist to create the lyric corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of characters in the corpus is: 564378\n",
      "The first 1000 characters of the corpus are as follows:\n",
      "\n",
      " I know your eyes in the morning sun\n",
      "I feel you touch me in the pouring rain\n",
      "And the moment that you wander far from me\n",
      "I wanna feel you in my arms again\n",
      "\n",
      "And you come to me on a summer breeze\n",
      "Keep me warm in your love then you softly leave\n",
      "And it's me you need to show\n",
      "How deep is your love\n",
      "\n",
      "How deep is your love, how deep is your love\n",
      "I really mean to learn\n",
      "'Cause we're living in a world of fools\n",
      "Breaking us down\n",
      "When they all should let us be\n",
      "We belong to you and me\n",
      "\n",
      "I believe in you\n",
      "And you know the door to my very soul\n",
      "You're the light in the deepest darkest hour\n",
      "You're my savior when I fall\n",
      "\n",
      "And you may not think\n",
      "That I care for you\n",
      "When you know down inside that I really do\n",
      "And it's me you need to show\n",
      "How deep is your love\n",
      "\n",
      "How deep is your love, how deep is your love\n",
      "I really mean to learn\n",
      "'Cause we're living in a world of fools\n",
      "Breaking us down\n",
      "When they all should let us be\n",
      "We belong to you and me\n",
      "\n",
      "And you come to me on a summer breeze\n",
      "Keep me warm in your love then you softly\n"
     ]
    }
   ],
   "source": [
    "# Collect all lyrics from selected artist\n",
    "selected_artist = \"Bee Gees\"\n",
    "lyrics_artist = lyrics_popular[lyrics_popular.Artist==selected_artist]['Lyric'].values.tolist()\n",
    "text = \"\"\n",
    "for i in range (len(lyrics_artist)):\n",
    "    text += lyrics_artist[i]+\"\\n\\n\"\n",
    "lines = text.split(\"\\n\")\n",
    "with open(\"lyrics.txt\",'w', encoding=\"utf-8\") as f:\n",
    "    for line in lines:\n",
    "        f.write(line)\n",
    "        f.write(\"\\n\")\n",
    "print('Total number of characters in the corpus is:',len(text))\n",
    "print('The first 1000 characters of the corpus are as follows:\\n\\n',text[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vecterize the text corpus\n",
    "- Create a vocabulary for all unique characters in the corpus\n",
    "- assign an integer for each charcter\n",
    "- text_as_int to vectorize the text corpus\n",
    "- idx2char (map from integer to char) for decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of unique characters in the corpus is 93\n",
      "A slice of the unique characters set:\n",
      " ['\\n', ' ', '!', '\"', '&', \"'\", '(', ')', '*', '+']\n"
     ]
    }
   ],
   "source": [
    "# The unique characters in the corpus\n",
    "vocab = sorted(set(text))\n",
    "print ('The number of unique characters in the corpus is', len(vocab))\n",
    "print('A slice of the unique characters set:\\n', vocab[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mapping from unique characters to indices\n",
    "char2idx = {u:i for i, u in enumerate(vocab)}\n",
    "# Make a copy of the unique set elements in NumPy array format for later use in the decoding the predictions\n",
    "idx2char = np.array(vocab)\n",
    "# Vectorize the text with a for loop\n",
    "text_as_int = np.array([char2idx[c] for c in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training examples / targets\n",
    "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int) \n",
    "# for i in char_dataset.take(5): \n",
    "#   print(i.numpy())\n",
    "seq_length = 100 # The max. length for single input\n",
    "# examples_per_epoch = len(text)//(seq_length+1) # double-slash for “floor” division\n",
    "sequences = char_dataset.batch(seq_length+1, drop_remainder=True) \n",
    "# for item in sequences.take(5): \n",
    "#   print(repr(''.join(idx2char[item.numpy()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_input_target(chunk):\n",
    "  input_text = chunk[:-1]\n",
    "  target_text = chunk[1:]\n",
    "  return input_text, target_text\n",
    "\n",
    "dataset = sequences.map(split_input_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BatchDataset element_spec=(TensorSpec(shape=(64, 100), dtype=tf.int64, name=None), TensorSpec(shape=(64, 100), dtype=tf.int64, name=None))>\n"
     ]
    }
   ],
   "source": [
    "BUFFER_SIZE = 10000 # TF shuffles the data only within buffers\n",
    "\n",
    "BATCH_SIZE = 64 # Batch size\n",
    "\n",
    "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
    "\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Length of the vocabulary in chars\n",
    "vocab_size = len(vocab)\n",
    "# The embedding dimension\n",
    "embedding_dim = 256\n",
    "# Number of RNN units\n",
    "rnn_units = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "  model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
    "                              batch_input_shape=[batch_size, None]),\n",
    "    tf.keras.layers.GRU(rnn_units,\n",
    "                        return_sequences=True,\n",
    "                        stateful=True,\n",
    "                        recurrent_initializer='glorot_uniform'),\n",
    "    tf.keras.layers.Dense(vocab_size)\n",
    "  ])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (64, None, 256)           23808     \n",
      "                                                                 \n",
      " gru (GRU)                   (64, None, 1024)          3938304   \n",
      "                                                                 \n",
      " dense (Dense)               (64, None, 93)            95325     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,057,437\n",
      "Trainable params: 4,057,437\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model(\n",
    "    vocab_size = len(vocab), # no. of unique characters\n",
    "    embedding_dim=embedding_dim, # 256\n",
    "    rnn_units=rnn_units, # 1024\n",
    "    batch_size=BATCH_SIZE)  # 64 for the traning\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### About the model layers:\n",
    "- Embedding Layer: serves as the input layer, accepting input values (in number format) and convert them into vectors.\n",
    "- GRU layer: an RNN layer filled with 1024 Gradient Descent Units\n",
    "- Dense layer: to output the result, with vocab_size outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model and save the weights\n",
    "- Adam as optimizer\n",
    "- Sparse categorical crossentropy function as loss function.\n",
    " - sparse categorical cross-entropy is used when truth labels are integer encoded like in this model\n",
    " - Class problemCategorical cross-entropy is used when true labels are one-hot encoded like [0,0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(labels, logits):\n",
    "  return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
    "\n",
    "# example_batch_loss  = loss(target_example_batch, example_batch_predictions)\n",
    "# print(\"Prediction shape: \", example_batch_predictions.shape, \" (batch_size, sequence_length, vocab_size)\")\n",
    "# print(\"scalar_loss:      \", example_batch_loss.numpy().mean())\n",
    "\n",
    "model.compile(optimizer='adam', loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory where the checkpoints will be saved\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "# Name of the checkpoint files\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "\n",
    "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "87/87 [==============================] - 80s 892ms/step - loss: 3.0076\n",
      "Epoch 2/30\n",
      "87/87 [==============================] - 77s 884ms/step - loss: 2.1248\n",
      "Epoch 3/30\n",
      "87/87 [==============================] - 77s 881ms/step - loss: 1.8731\n",
      "Epoch 4/30\n",
      "87/87 [==============================] - 78s 885ms/step - loss: 1.6690\n",
      "Epoch 5/30\n",
      "87/87 [==============================] - 77s 883ms/step - loss: 1.5167\n",
      "Epoch 6/30\n",
      "87/87 [==============================] - 77s 879ms/step - loss: 1.4026\n",
      "Epoch 7/30\n",
      "87/87 [==============================] - 77s 877ms/step - loss: 1.3103\n",
      "Epoch 8/30\n",
      "87/87 [==============================] - 77s 882ms/step - loss: 1.2340\n",
      "Epoch 9/30\n",
      "87/87 [==============================] - 76s 866ms/step - loss: 1.1647\n",
      "Epoch 10/30\n",
      "87/87 [==============================] - 75s 860ms/step - loss: 1.0990\n",
      "Epoch 11/30\n",
      "87/87 [==============================] - 75s 851ms/step - loss: 1.0379\n",
      "Epoch 12/30\n",
      "87/87 [==============================] - 75s 852ms/step - loss: 0.9778\n",
      "Epoch 13/30\n",
      "87/87 [==============================] - 74s 847ms/step - loss: 0.9194\n",
      "Epoch 14/30\n",
      "87/87 [==============================] - 75s 852ms/step - loss: 0.8584\n",
      "Epoch 15/30\n",
      "87/87 [==============================] - 75s 852ms/step - loss: 0.8012\n",
      "Epoch 16/30\n",
      "87/87 [==============================] - 74s 846ms/step - loss: 0.7456\n",
      "Epoch 17/30\n",
      "87/87 [==============================] - 74s 846ms/step - loss: 0.6907\n",
      "Epoch 18/30\n",
      "87/87 [==============================] - 74s 842ms/step - loss: 0.6383\n",
      "Epoch 19/30\n",
      "87/87 [==============================] - 75s 849ms/step - loss: 0.5915\n",
      "Epoch 20/30\n",
      "87/87 [==============================] - 74s 841ms/step - loss: 0.5488\n",
      "Epoch 21/30\n",
      "87/87 [==============================] - 74s 846ms/step - loss: 0.5088\n",
      "Epoch 22/30\n",
      "87/87 [==============================] - 74s 844ms/step - loss: 0.4754\n",
      "Epoch 23/30\n",
      "87/87 [==============================] - 74s 843ms/step - loss: 0.4446\n",
      "Epoch 24/30\n",
      "87/87 [==============================] - 74s 844ms/step - loss: 0.4197\n",
      "Epoch 25/30\n",
      "87/87 [==============================] - 74s 841ms/step - loss: 0.4006\n",
      "Epoch 26/30\n",
      "87/87 [==============================] - 74s 842ms/step - loss: 0.3816\n",
      "Epoch 27/30\n",
      "87/87 [==============================] - 74s 838ms/step - loss: 0.3663\n",
      "Epoch 28/30\n",
      "87/87 [==============================] - 74s 840ms/step - loss: 0.3544\n",
      "Epoch 29/30\n",
      "87/87 [==============================] - 74s 845ms/step - loss: 0.3431\n",
      "Epoch 30/30\n",
      "87/87 [==============================] - 74s 841ms/step - loss: 0.3349\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 30\n",
    "history = model.fit(dataset, \n",
    "                    epochs=EPOCHS, \n",
    "                    callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate New Text\n",
    "- Use a new model with batch_size = 1\n",
    "- use saved weights\n",
    "- use temperature to adjust variability of the predictions \n",
    " - a categorical distribution to predict the character returned by the model\n",
    " - higher increases the probability of selecting a less likely character\n",
    " - lower --> more predictable\n",
    "- Select output length\n",
    "- Select start words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./training_checkpoints/ckpt_30'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Locate saved weights\n",
    "tf.train.latest_checkpoint(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (1, None, 256)            23808     \n",
      "                                                                 \n",
      " gru_1 (GRU)                 (1, None, 1024)           3938304   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (1, None, 93)             95325     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,057,437\n",
      "Trainable params: 4,057,437\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
    "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "model.build(tf.TensorShape([1, None]))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, num_generate, temperature, start_string):\n",
    "  input_eval = [char2idx[s] for s in start_string] # string to numbers (vectorizing)\n",
    "  input_eval = tf.expand_dims(input_eval, 0) # dimension expansion\n",
    "  text_generated = [] # Empty string to store our results\n",
    "  model.reset_states() # Clears the hidden states in the RNN\n",
    "\n",
    "  for i in range(num_generate): #Run a loop for number of characters to generate\n",
    "    predictions = model(input_eval) # prediction for single character\n",
    "    predictions = tf.squeeze(predictions, 0) # remove the batch dimension\n",
    "\n",
    "    # using a categorical distribution to predict the character returned by the model\n",
    "    # higher temperature increases the probability of selecting a less likely character\n",
    "    # lower --> more predictable\n",
    "    predictions = predictions / temperature\n",
    "    predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
    "\n",
    "    # The predicted character as the next input to the model\n",
    "    # along with the previous hidden state\n",
    "    # So the model makes the next prediction based on the previous character\n",
    "    input_eval = tf.expand_dims([predicted_id], 0) \n",
    "    # Also devectorize the number and add to the generated text\n",
    "    text_generated.append(idx2char[predicted_id]) \n",
    "\n",
    "  return (start_string + ''.join(text_generated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Love is sungry\n",
      "\n",
      "When I see you everywhere\n",
      "\n",
      "Jimmett dakes\n",
      "You're my angel on the sun\n",
      "We turn to stand alone.\n",
      "\n",
      "\n",
      "\n",
      "Hell on my mind , a stay.\n",
      "\n",
      "When I see you every mornin,\n",
      "\n",
      "I can see a miracle , a dialone to do theak to me\n",
      "I can be strong, ohat, my story 'rn't like to be over.\n",
      "Lire I can get you there\n",
      "\n",
      "So forever haven't got a friend in me\n",
      "\n",
      "Warm ride, warm ride, we can reach the highest silent nothing of life\n",
      "\n",
      "And when you're out at nightta\n",
      "If you're not here by me\n",
      "It's understand what my friends.\n",
      "\n",
      "I was there inside\n",
      "\n",
      "Good man I don't change my way\n",
      "There's a fire line tomorrow\n",
      "de life , whoa\n",
      "You did when she shakes all over me , in Can just get ignited,\n",
      "Let this be my prayer, I will stay, I will go with the thoughts of leaves\n",
      "I have feed, look at us now\n",
      "We're all along with your life\n",
      "Come on our shoulders for me\n",
      "\n",
      "So want me, I can't let go of you\n",
      "I'm just a clown that used to be\n",
      "I stumble is just\n",
      "Like the dreams , we'll be the secret -- goes living on\n",
      "\n",
      "No, you can't keep a good man down\n",
      "When yo\n"
     ]
    }
   ],
   "source": [
    "generated_text = generate_text(\n",
    "                    model, \n",
    "                    num_generate=1000, \n",
    "                    temperature=1, \n",
    "                    start_string=u\"Love\")\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### References:\n",
    "- Create Your Own Artificial Shakespeare in 10 Minutes with Natural Language Processing<br>\n",
    "https://towardsdatascience.com/create-your-own-artificial-shakespeare-in-10-minutes-with-natural-language-processing-1fde5edc8f28\n",
    "-dataset: <br>\n",
    "https://www.kaggle.com/datasets/neisse/scrapped-lyrics-from-6-genres?select=lyrics-data.csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
