{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da197a28",
   "metadata": {},
   "source": [
    "# Using Classification to Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6fe1b9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import sys\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "\n",
    "from sklearn.feature_extraction import text      \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c8ca393",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of               Artist Genres                            SName  \\\n",
       "0       Shawn Mendes    Pop                    It'll Be Okay   \n",
       "1       Shawn Mendes    Pop  There's Nothing Holdin' Me Back   \n",
       "2       Shawn Mendes    Pop                 Treat You Better   \n",
       "3       Shawn Mendes    Pop                         Stitches   \n",
       "4       Shawn Mendes    Pop                   Never Be Alone   \n",
       "...              ...    ...                              ...   \n",
       "2539      Dima Bilan    Pop                          Trouble   \n",
       "2540  Lene Alexandra    Pop                 Hot Boy Hot Girl   \n",
       "2541  Lene Alexandra    Pop                  My Boobs Are Ok   \n",
       "2542  Lene Alexandra    Pop           Sexy Naughty Bitchy Me   \n",
       "2543  Lene Alexandra    Pop                 Sillycone Valley   \n",
       "\n",
       "                                                  Lyric  \n",
       "0     Are we gonna make it?\\nIs this gonna hurt?\\nOh...  \n",
       "1     I wanna follow where she goes\\nI think about h...  \n",
       "2     I won't lie to you\\nI know he's just not right...  \n",
       "3     I thought that I've been hurt before\\nBut no o...  \n",
       "4     I promise that one day I'll be around\\nI'll ke...  \n",
       "...                                                 ...  \n",
       "2539  She (she, she) she like to model for me (me, m...  \n",
       "2540  i need a hot boy, i need a hot girl\\ni need a ...  \n",
       "2541  Hello!\\nMy Boobs, my boobs\\nMy boobs are ok\\nM...  \n",
       "2542  I pick all my skirts to be a little too sexy\\n...  \n",
       "2543  Thunder of love is here again\\nTake my hand an...  \n",
       "\n",
       "[2544 rows x 4 columns]>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Code from Chenghui\n",
    "lyrics = pd.read_csv('lyrics-data.csv') \n",
    "lyrics=lyrics.query(\"language=='en'\")\n",
    "artists = pd.read_csv(\"artists-data.csv\")\n",
    "\n",
    "partists = (artists[artists[\"Genres\"]==\"Pop\"])\n",
    "psongs = pd.merge(lyrics,partists,left_on=\"ALink\",right_on=\"Link\")\n",
    "\n",
    "#Getting the categories we want\n",
    "psongs = (psongs[[\"Artist\",\"Genres\",\"SName\",\"Lyric\"]])\n",
    "#removing empty and songs with no lyrics\n",
    "psongs = psongs.dropna()\n",
    "psongs = psongs[psongs[\"Lyric\"]!='Instrumental']\n",
    "\n",
    "psongs.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da0934a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of                     Artist Genres                                  SName  \\\n",
       "0                   Fugees    Rap        Killing Me Softly With His Song   \n",
       "1                   Fugees    Rap                          How Many Mics   \n",
       "2                   Fugees    Rap                           Ready Or Not   \n",
       "3                   Fugees    Rap                     Vocab (LP Version)   \n",
       "4                   Fugees    Rap                                Zealots   \n",
       "...                    ...    ...                                    ...   \n",
       "2007  Dipset/The Diplomats    Rap                               Who I Am   \n",
       "2008  Dipset/The Diplomats    Rap                                Worried   \n",
       "2009  Dipset/The Diplomats    Rap  Wouldn't You Like To Be A Gangsta Too   \n",
       "2010  Dipset/The Diplomats    Rap              Ya'll Can't Live His Life   \n",
       "2011  Dipset/The Diplomats    Rap                        You Make Me Say   \n",
       "\n",
       "                                                  Lyric  \n",
       "0     Strumming my pain with his fingers\\nSinging my...  \n",
       "1     Intro: Wyclef Jean\\nPick up your microphones\\n...  \n",
       "2     Ready or not, here I come, you can't hide\\nGon...  \n",
       "3     Chorus\\nYou got the vocab\\nI got the vocab\\nYo...  \n",
       "4     CLEF]\\nAnother MC lose his life tonight, lord\\...  \n",
       "...                                                 ...  \n",
       "2007  {background lady singing ba-da-baba & Who am i...  \n",
       "2008  [DukeDaGod]\\nLet's get back to doin what we do...  \n",
       "2009  Ok\\nIm sure u heard sure u heard fukker\\nHe's ...  \n",
       "2010  [Cam'Ron: Intro]\\nKILLA... DIPSET... MY NIGGA ...  \n",
       "2011  (feat. JR Writer)\\n\\n[Intro: JR Writer]\\nDipse...  \n",
       "\n",
       "[2012 rows x 4 columns]>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rartists = (artists[artists[\"Genres\"]==\"Rap\"])\n",
    "rsongs = pd.merge(lyrics,rartists,left_on=\"ALink\",right_on=\"Link\")\n",
    "\n",
    "#Getting the categories we want\n",
    "rsongs = (rsongs[[\"Artist\",\"Genres\",\"SName\",\"Lyric\"]])\n",
    "#removing empty and songs with no lyrics\n",
    "rsongs = rsongs.dropna()\n",
    "rsongs = rsongs[rsongs[\"Lyric\"]!='Instrumental']\n",
    "\n",
    "rsongs.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8729eef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Pop:\n",
      "(2544, 4)\n",
      "Shape of Rap:\n",
      "(2012, 4)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of Pop:\")\n",
    "print((psongs).shape)\n",
    "print(\"Shape of Rap:\")\n",
    "print((rsongs).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca6243ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Are we gonna make it?\\nIs this gonna hurt?\\nOh, we can try to sedate it\\nBut that never works\\nYeah\\n\\nI start to imagine a world where we don't collide\\nIt's making me sick but we'll heal and the sun will rise\\n\\nIf you tell me you're leaving, I'll make it easy\\nIt'll be okay\\nIf we can't stop the bleeding\\nWe don't have to fix it, we don't have to stay\\nI will love you either way\\nOoh-ooh, it'll be oh, be okay\\nOoh-ooh\\n\\nOh, the future we dreamed of is fading to black\\nOh-oh, oh-oh, oh\\nOh, thеre's nothing more painful\\nNothing more painful, oh-woah (Oh-woah)\\n\\nI start to imaginе a world where we don't collide\\nAnd it's making me sick but we'll heal and the sun will rise\\n\\nIf you tell me you're leaving, I'll make it easy\\nIt'll be okay (It'll be okay)\\nAnd if we can't stop the bleeding\\nWe don't have to fix it, we don't have to stay (Don't have to stay)\\nI will love you either way\\nOoh-ooh, it'll be oh, be okay\\nOoh-ooh\\n\\nI will love you either way\\nIt might be so sweet\\nIt might be so bitter\\nI will love you either way\\nIt might be so sweet\\nIt might be so bitter (Ooh-ooh)\\n\\nOh, if the future we've dreamed of is fading to black\\nI will love you either way\"\n",
      " \"I wanna follow where she goes\\nI think about her and she knows it\\nI wanna let her take control\\n'cause every time that she gets close, yeah\\n\\nShe pulls me in enough to keep me guessing\\nMaybe I should stop and start confessing\\nConfessing, yeah\\n\\nOh, I've been shaking\\nI love it when you go crazy\\nYou take all my inhibitions\\nBaby, there's nothing holding me back\\nYou take me places\\nThat tear up my reputation\\nManipulate my decisions\\nBaby, there's nothing holding me back\\nThere's nothing holding me back\\nThere's nothing holding me back\\n\\nShe says that she's never afraid\\nJust picture everybody naked\\nShe really doesn't like to wait\\nNot really into hesitations\\n\\nPulls me in enough to keep me guessing\\nAnd maybe I should stop and start confessing\\nConfessing, yeah\\n\\nOh, I've been shaking\\nI love it when you go crazy\\nYou take all my inhibitions\\nBaby, there's nothing holding me back\\nYou take me places\\nThat tear up my reputation\\nManipulate my decisions\\nBaby, there's nothing holding me back\\nThere's nothing holding me back\\n\\n\\n'Cause if we lost our minds\\nAnd we took it way too far\\nI know we'd be alright\\nKnow we would be alright\\nIf you are by my side\\nAnd we stumbled in the dark\\nI know we'd be alright\\nOh no we would be alright\\n'Cause if we lost our minds\\nAnd we took it way too far\\nI know we'd be alright\\nI know we would be alright\\nIf you are by my side\\nAnd we stumbled in the dark\\nI know we'd be alright\\nWe would be alright\\n\\nOh, I've been shaking\\nI love it when you go crazy\\nYou take all my inhibitions\\nBaby, there's nothing holding me back\\nYou take me places that tear up my reputation\\nManipulate my decisions\\nBaby, there's nothing holding me back\\nThere's nothing holding me back\\nI feel so free when you're with me, baby\\n\\nBaby, there's nothing holding me back\"\n",
      " \"I won't lie to you\\nI know he's just not right for you\\nAnd you can tell me if I'm off\\nBut I see it on your face\\nWhen you say that he's the one that you want\\nAnd you're spending all your time\\nIn this wrong situation\\nAnd anytime you want it to stop\\n\\nI know I can treat you better\\nThan he can\\nAnd any girl like you\\ndeserves a gentleman\\nTell me why are we wasting time\\nOn all your wasted crying\\nWhen you should be with me instead\\nI know I can treat you better\\nBetter than he can\\n\\nI'll stop time for you\\nThe second you say\\nYou'd like me to\\nI just wanna give you the loving\\nThat you're missing\\nBaby, just to wake up with you\\nWould be everything I need\\nAnd this could be so different\\nTell me what you want to do\\n\\n'Cause I know I can treat you better\\nThan he can\\nAnd any girl like you\\ndeserves a gentleman\\nTell me why are we wasting time\\nOn all your wasted crying\\nWhen you should be with me instead\\nI know I can treat you better\\nBetter than he can\\nBetter than he can\\n\\nGive me a sign\\nTake my hand, we'll be fine\\nPromise I won't let you down\\nJust know that you don't\\nHave to do this alone\\nPromise I'll never let you down\\n\\n\\n'Cause I know I can treat you better\\nThan he can\\nAnd any girl like you\\ndeserves a gentleman\\nTell me why are we wasting time\\nOn all your wasted crying\\nWhen you should be with me instead\\nI know I can treat you better\\nBetter than he can\\nBetter than he can\\nBetter than he can\\nBetter than he can\\nBetter than he can\"\n",
      " ...\n",
      " \"Say it takes two to tango\\nBut a crew to bang, yo\\nSuperstar shootout\\nOvertime at Durango\\nClear out/the box out\\nPractice at the range - yo\\nGet the D to step back\\nUnless they be deranged, dough\\nRae me fa so la ti dough\\nThe chiza/rarely do missa\\nMoney earner isa\\nBarn burner\\nHighlighted by the headturner\\nEvery step you take\\nTelevised by Ted Turner\\nTBS and TNT\\nSunday drain the tray\\nBut drew the foul on NBC\\nAin't no stoppin me\\nI told yall\\nI close the door on the series\\nSwept but they ain't here me\\nIn case you forgot\\nThis shot is hot\\nBoo yoww\\nLike Stuart on the Scott\\nHaves and have not\\nGo cat go\\nLet the legend grow\\nGame it like you game it\\nBetter let em all know\\n\\n1 for the chiza\\n2 for the flow\\n3 to get the heads ready\\nGo cat go\\nGo cat go\\n\\nGo cat go\\nHigh and down low\\nDo it like you did\\nOn the brother wit the fro\\nGood job baby\\nGet the crowd crazy\\nPut that finger up at the section ladies\\nScream c'mon scream\\nAt the chisa and the cream\\nRaised up in Brooklyn\\nBut be ballin down in Queens\\nWhite man's burden\\nBe a black man's dream\\nBadge over troubled green\\nBe a triple team\\nSuits and ties\\nSee the envy in the eyes\\nControllin guys while the\\nBuyers lie about the size\\nHigh priced Adonises\\nUnkept promises\\nBoxscore forgets all the no name threats\\nPuttin numbers up\\nTo get them numbers up\\nKeep bouncin\\nBut whos countin?\\n\\n1 for the chiza\\n2 for the flow\\n3 to get the heads ready\\nGo cat go\\nGo cat go\\n\\nGo cat go\\nHigh and down low\\nDo like you did\\nOn the brother\\nWith the fro\\n\\nGo cat go\\nLet the legend grow\\nGame it like you game it\\nBetter let em all know\\n\\nGo cat go\\nLet a player know\\nConey Island style\\nBefore you go pro\\n\\n\"\n",
      " \"Pudim\\n\\nAre you ready?\\nUptown, on the corner, uptown\\nUptown on the corner, uptown\\nI turn around and hear the sound of voices talkin bout who's goin to die next\\nCause the white man's got a God complex\\nTellin niggas screamin for help (help me, help me, help me, help me)\\nNigga go make your own help\\nShit you need it\\nI turn around and hear the sound of jukeboxes playin in bars\\nPimps parked outside in big pretty Flavor Flav cars\\nCleaner than a broke dick dog\\nSittin in a big fine frog\\nDressed very fine and fly in their Calvin Kani\\nNo matter how you flex\\nYo Jim\\nThey'll die next\\nCause the white man's got a God complex\\nUptown on the corner, uptown (X 4)\\nHey brother what you sport my man\\nI got just the thing for you\\nOnly cause you're 10 and 2\\nWhat ya gonna do baby\\nI got black ones\\nBrown ones\\nRed ones\\nYellow ones\\nI even got a white one\\nIf you want to buy some\\nYeah\\nThat's right\\n2 5 8 play it straight\\nGot it all worked out\\nI know what I'm talkin bout\\nYo I been readin my dream books\\nSo I ain't no way the kid is gonna get took\\nNigga what you mean\\nI didn't hit\\nNigga\\nYou full of shit\\nNigga\\nLick the ice (uh)\\nNow 7\\nCome on be nice and hit 11\\nWell what do you know\\nIt's lil Joe\\nEy my man\\nGot twenty dollars eh lil Joe don't blow\\nAh baby needs a new pair of shoes\\nAh pappas got the funky blues\\nAh mamma plays the crosswords in the news\\nSorry nigga you lose\\nThe line forms to the rear lady muther fuck your welfare check\\nCause the white man's got a God complex\\nUptown on the corner (X 4)\\nMr. Stein elevating a friend\\nBut is proud to be mine\\nBut you just want to cheat me cause I ain't your kind\\nDamn\\nI'm so poor\\nI don't know what the hell I'ma do anymore\\nNot from this day to the next\\nCause the white man's got a God complex\\n(vamp out)\\n\\n\"\n",
      " \"Ridenhour - Gary G-Wiz - H. Shocklee\\n\\nI gotta do what I gotta do (uh)\\nSo who the hell is you\\nTo tell me how my song is wrong\\nYou don't know\\nLayout & let the drummer go\\nYou think my rap's about stealin'\\nBut it's about feelin'\\nSometimes drug dealin'\\nBut few know how my flow\\nDon't get the proper review\\nI gotta do what I gotta do\\n\\nDo whatcha gotta do first\\nOoh\\nHere go da verse\\nI gotta do what I do best (uh)\\nKick da Nitti & Ness\\nThe danger zone\\nThey better leave me alone\\nI got posse\\nLus the feds had better watch me\\nI picked a bone wit' Arizona\\nDroppin' kickin' a mission\\nWit' no permission\\nI let 'em know why I did what I did\\nI got dialogue\\nGot 'em to even sing along\\n& got the semiautomatic\\nTongue to da young\\nWhen there's static\\nThey come & try to get some\\nThey had the nerve to call the president\\nAn' I wasn't hesitant\\nTo scream I was a resident\\n\\nSo-called power of the people\\nLookin' for the truth\\nLike guessin' my vest was never bulletproof\\nI'm edgin' close to the line\\n& it's fine time to know\\nWhy the hell & da f---\\nI try to battle so\\nMuch to touch never feedin'\\nA crutch to lean on me\\nExcuses is weak\\nThat's why my look is mean\\nTo the devils 'bout God\\nAnother reason why it's comin' hard\\nMy intellect doin' wreckin' effect\\n'Till it's through\\nGotta do what I gotta do\\n\\nI Gotta do what dey don't like\\n'Cause I got a mike\\nThe more I push\\n& the more you learn\\n& dey burn, you get another turn\\nTo take the helm recreate\\nThe realm of leaders\\nNot to say you never need us\\nBut in da mirror\\nYou can do it, it's so easy to start\\nYeah baby you can see it on\\nA flow chart\\nAnd just in case\\nThey ever get me in da middle\\nOf things before I go\\nYou know I'm gonna take a swang\\nUntil dey give what dey never\\nGave I refuse to be\\nA slave I hijacked\\nThe airwaves\\nLet ya know the dirt\\nSwept under the rug\\nGive the brothers a pound\\nMy sisters a lil' bigger hugs\\nMy rat a tat comin' right\\n& exact 'cause it's true\\nI gotta do what I gotta do\\n\\n\"]\n"
     ]
    }
   ],
   "source": [
    "#Creating out training data\n",
    "train_psongs_len = int(len(psongs)*0.4)\n",
    "train_rsongs_len = int(len(rsongs)*0.4)\n",
    "\n",
    "train_data = pd.concat([psongs.head(train_psongs_len),rsongs.head(train_rsongs_len)])\n",
    "print(train_data['Lyric'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de7cbbf1",
   "metadata": {},
   "source": [
    "### Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ab82221",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating our Vocab\n",
    "cv = CountVectorizer(strip_accents='ascii', lowercase=True, stop_words='english', analyzer='word')\n",
    "cv.fit(train_data['Lyric'].values)\n",
    "#bag of words\n",
    "bow = cv.transform(train_data['Lyric'].values) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a263227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 : Logistic Regression\n",
      "2 : Decision Tree\n",
      "3 : Random Forest\n",
      "4 : SVC\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "models = {'Logistic Regression':LogisticRegression(max_iter=500),\n",
    "          'Decision Tree': DecisionTreeClassifier(),\n",
    "          'Random Forest': RandomForestClassifier(),\n",
    "          'SVC': SVC()}\n",
    "\n",
    "for i,m in enumerate(models.keys()):\n",
    "    print(i+1, \":\", m)\n",
    "    models[m].fit(bow.toarray(), train_data[\"Genres\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f944da",
   "metadata": {},
   "source": [
    "# Accuracy of Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa76a6cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "She was my once in a lifetime\n",
      "Happy ending come true\n",
      "Oh I guess I should have told her\n",
      "I thought she knew\n",
      "\n",
      "She said I took her for granted\n",
      "That's the last thing I would do\n",
      "Whoa I'll never understand i\n"
     ]
    }
   ],
   "source": [
    "#Creating our test data\n",
    "test_data = pd.concat([psongs.iloc[train_psongs_len:len(psongs)],rsongs.iloc[train_rsongs_len:len(rsongs)]])\n",
    "print(test_data['Lyric'].values[0][0:200])\n",
    "\n",
    "test_bow = cv.transform(test_data['Lyric'].values) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f244e5d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "Decision Tree\n",
      "Random Forest\n",
      "SVC\n",
      "---Accuracy Scores---\n",
      "{'Logistic Regression': 0.8486288848263254, 'Decision Tree': 0.8106032906764168, 'Random Forest': 0.8745886654478976, 'SVC': 0.8288848263254114}\n"
     ]
    }
   ],
   "source": [
    "#Get the scores of each model\n",
    "accuracy = {}\n",
    "test_data = test_data[['Artist', 'SName','Genres']] #[[\"Artist\",\"Genres\",\"SName\",\"Lyric\"]])\n",
    "for m in models.keys():\n",
    "    print(m)\n",
    "    pred_genre= models[m].predict(test_bow.toarray())\n",
    "    test_data[m]=pred_genre\n",
    "    accuracy[m]=accuracy_score(test_data['Genres'],pred_genre)\n",
    "print (\"---Accuracy Scores---\")\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2066190",
   "metadata": {},
   "source": [
    "Seems like Random Forest is the best. Let's see if we can predit the genre\n",
    "of our generated text. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab6baf49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 RNN  \\\n",
      "0  Hah, Yeah, what, oh, so.. what you can kang to...   \n",
      "1  Anohownerely fills flickin' all my love when y...   \n",
      "2  And we got nothin' to rish high and I play\\nI ...   \n",
      "3  Loveg “tell ya\\nSlopt to have me\\nniggas be fr...   \n",
      "4  Lover you\"who knows what lies a numberod\\nThey...   \n",
      "\n",
      "                                                LSTM  \\\n",
      "0  Bring me the night and day\\nAll the pain , tha...   \n",
      "1  You be there for me to\\nNow we don't make me w...   \n",
      "2  \\nYou be there for me to\\nNow we don't make me...   \n",
      "3  And we still in me the - Boy\\nI don't know whe...   \n",
      "4  I just won't be so true\\nYou make me one more ...   \n",
      "\n",
      "                                               GPT-2  \n",
      "0  Even though you do,I'm not dead. You just come...  \n",
      "1  Fifty-five times I'm going out for love and wa...  \n",
      "2  Don't tell anyone else what to do is a lie  Bu...  \n",
      "3                                                NaN  \n",
      "4                                                NaN  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RNN</th>\n",
       "      <th>LSTM</th>\n",
       "      <th>GPT-2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hah, Yeah, what, oh, so.. what you can kang to...</td>\n",
       "      <td>Bring me the night and day\\nAll the pain , tha...</td>\n",
       "      <td>Even though you do,I'm not dead. You just come...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Anohownerely fills flickin' all my love when y...</td>\n",
       "      <td>You be there for me to\\nNow we don't make me w...</td>\n",
       "      <td>Fifty-five times I'm going out for love and wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>And we got nothin' to rish high and I play\\nI ...</td>\n",
       "      <td>\\nYou be there for me to\\nNow we don't make me...</td>\n",
       "      <td>Don't tell anyone else what to do is a lie  Bu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 RNN  \\\n",
       "0  Hah, Yeah, what, oh, so.. what you can kang to...   \n",
       "1  Anohownerely fills flickin' all my love when y...   \n",
       "2  And we got nothin' to rish high and I play\\nI ...   \n",
       "\n",
       "                                                LSTM  \\\n",
       "0  Bring me the night and day\\nAll the pain , tha...   \n",
       "1  You be there for me to\\nNow we don't make me w...   \n",
       "2  \\nYou be there for me to\\nNow we don't make me...   \n",
       "\n",
       "                                               GPT-2  \n",
       "0  Even though you do,I'm not dead. You just come...  \n",
       "1  Fifty-five times I'm going out for love and wa...  \n",
       "2  Don't tell anyone else what to do is a lie  Bu...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated = pd.read_csv('some_RNN_generated_data.csv') \n",
    "print(generated.head())\n",
    "generated.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "29969eac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "['Pop' 'Pop' 'Pop' 'Rap' 'Pop']\n",
      "Percent match:  0.6\n",
      "Decision Tree\n",
      "['Rap' 'Pop' 'Pop' 'Rap' 'Pop']\n",
      "Percent match:  0.8\n",
      "Random Forest\n",
      "['Pop' 'Pop' 'Pop' 'Rap' 'Pop']\n",
      "Percent match:  0.6\n",
      "SVC\n",
      "['Pop' 'Pop' 'Pop' 'Rap' 'Pop']\n",
      "Percent match:  0.6\n"
     ]
    }
   ],
   "source": [
    "\n",
    "RNN_real_genre = [\"Rap\",\"Pop\",\"Pop\",\"Pop\",\"Pop\"]\n",
    "RNN_bow = cv.transform(generated['RNN'].values)\n",
    "for m in models.keys():\n",
    "    print(m)\n",
    "    pred_genre= models[m].predict(RNN_bow.toarray())\n",
    "    print(pred_genre)\n",
    "    print(\"Percent match: \", np.mean( pred_genre == RNN_real_genre ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "280ba533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "['Pop' 'Pop' 'Pop' 'Rap' 'Pop']\n",
      "Percent match:  1.0\n",
      "Decision Tree\n",
      "['Pop' 'Pop' 'Pop' 'Rap' 'Pop']\n",
      "Percent match:  1.0\n",
      "Random Forest\n",
      "['Pop' 'Pop' 'Pop' 'Rap' 'Pop']\n",
      "Percent match:  1.0\n",
      "SVC\n",
      "['Pop' 'Pop' 'Pop' 'Rap' 'Pop']\n",
      "Percent match:  1.0\n"
     ]
    }
   ],
   "source": [
    "LSTM_real_genre = [\"Pop\",\"Pop\",\"Pop\",\"Rap\",\"Pop\"]\n",
    "LSTM_bow = cv.transform(generated['LSTM'].values)\n",
    "for m in models.keys():\n",
    "    print(m)\n",
    "    pred_genre= models[m].predict(LSTM_bow.toarray())\n",
    "    print(pred_genre)\n",
    "    print(\"Percent match: \", np.mean( pred_genre == LSTM_real_genre ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "19aae107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "['Pop' 'Pop' 'Pop']\n",
      "Percent match:  1.0\n",
      "Decision Tree\n",
      "['Pop' 'Pop' 'Pop']\n",
      "Percent match:  1.0\n",
      "Random Forest\n",
      "['Pop' 'Pop' 'Pop']\n",
      "Percent match:  1.0\n",
      "SVC\n",
      "['Pop' 'Pop' 'Pop']\n",
      "Percent match:  1.0\n"
     ]
    }
   ],
   "source": [
    "GPT_real_genre = [\"Pop\",\"Pop\",\"Pop\"]\n",
    "temp=(generated['GPT-2'].dropna())\n",
    "GPT_bow = cv.transform(temp.values)\n",
    "for m in models.keys():\n",
    "    print(m)\n",
    "    pred_genre= models[m].predict(GPT_bow.toarray())\n",
    "    print(pred_genre)\n",
    "    print(\"Percent match: \", np.mean( pred_genre == GPT_real_genre ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b0b1f66",
   "metadata": {},
   "source": [
    "# More Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bded27ed",
   "metadata": {},
   "source": [
    "### BERT SCORE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5f2aa1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install bert_score\n",
    "from datasets import load_metric\n",
    "\n",
    "bertscore_metric = load_metric('bertscore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f9fca804",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN:\n",
      "[0.7927799224853516, 0.8087143301963806, 0.8047899603843689, 0.7679463028907776, 0.7915160655975342]\n",
      "LSTM:\n",
      "[0.8123180866241455, 0.8202456831932068, 0.8177557587623596, 0.7911052107810974, 0.7901195287704468]\n",
      "GPT-2:\n",
      "[0.7938002347946167, 0.7782478332519531, 0.7792690396308899]\n"
     ]
    }
   ],
   "source": [
    "bert_scores = bertscore_metric.compute(predictions=generated['RNN'].values, references=psongs[\"Lyric\"][:5].values, lang=\"en\")\n",
    "# Normally, we use the f1-score attribute\n",
    "print(\"RNN:\")\n",
    "print(bert_scores['f1'])\n",
    "\n",
    "bert_scores = bertscore_metric.compute(predictions=generated['LSTM'].values, references=psongs[\"Lyric\"][:5].values, lang=\"en\")\n",
    "# Normally, we use the f1-score attribute\n",
    "print(\"LSTM:\")\n",
    "print(bert_scores['f1'])\n",
    "\n",
    "\n",
    "artist =  \"Lana Del Rey\"\n",
    "\n",
    "# code from Chenghui\n",
    "lyrics = pd.read_csv('lyrics-data.csv') \n",
    "lyrics=lyrics.query(\"language=='en'\")\n",
    "artists = pd.read_csv(\"artists-data.csv\")\n",
    "lyrics_df = pd.merge(lyrics,artists,left_on=\"ALink\",right_on=\"Link\")\n",
    "lyrics_df = lyrics_df[[\"Artist\",\"Genres\",\"Popularity\",\"Songs\",\"SName\",\"Lyric\"]]\n",
    "lyrics_popular=lyrics_df.query(f\"Artist=='{artist}'\")\n",
    "lyrics_popular=lyrics_popular.sort_values(['Songs','Artist'], ascending=[False,True])\n",
    "\n",
    "bert_scores = bertscore_metric.compute(predictions=temp.values, references=lyrics_popular[\"Lyric\"][:3].values, lang=\"en\")\n",
    "# Normally, we use the f1-score attribute\n",
    "print(\"GPT-2:\")\n",
    "print(bert_scores['f1'])\n",
    "\n",
    "#Using first x songs as referencce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "648c3eec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN:\n",
      "[0.7642351388931274, 0.7681809663772583, 0.7660707831382751, 0.7490460276603699, 0.7736159563064575]\n",
      "LSTM:\n",
      "[0.7846565842628479, 0.7853808403015137, 0.7853808403015137, 0.7669862508773804, 0.7778748869895935]\n",
      "GPT-2 (Lana Del Rey):\n",
      "[0.7807826995849609, 0.7799481749534607, 0.778856635093689]\n"
     ]
    }
   ],
   "source": [
    "flattened = psongs[\"Lyric\"]\n",
    "flattened = np.reshape(flattened.values, (1,flattened.shape[0]))\n",
    "flattened = [flattened,flattened,flattened,flattened,flattened]\n",
    "\n",
    "lana = lyrics_popular[\"Lyric\"]\n",
    "lana = np.reshape(lana.values, (1,lana.shape[0]))\n",
    "lana = [lana,lana,lana]\n",
    "\n",
    "bert_scores = bertscore_metric.compute(predictions=generated['RNN'].values, references=flattened, lang=\"en\")\n",
    "# Normally, we use the f1-score attribute\n",
    "print(\"RNN:\")\n",
    "print(bert_scores['f1'])\n",
    "\n",
    "bert_scores = bertscore_metric.compute(predictions=generated['LSTM'].values, references=flattened, lang=\"en\")\n",
    "# Normally, we use the f1-score attribute\n",
    "print(\"LSTM:\")\n",
    "print(bert_scores['f1'])\n",
    "\n",
    "temp=(generated['GPT-2'].dropna())\n",
    "\n",
    "bert_scores = bertscore_metric.compute(predictions=temp.values, references=lana, lang=\"en\")\n",
    "# Normally, we use the f1-score attribute\n",
    "print(\"GPT-2 (Lana Del Rey):\")\n",
    "print(bert_scores['f1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50e62e7",
   "metadata": {},
   "source": [
    "#### BERT SCORE RESULTS\n",
    "\n",
    "Our results are okay. However, the problem with BERT Score is that you need references for the generation to compare to. Our models just generate text from training without matching reference. \n",
    "\n",
    "We also tried using the entire lyric corpus as a reference but it also does not perform well.\n",
    "\n",
    "Therefore, this is not a really good evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a016d83e",
   "metadata": {},
   "source": [
    "### Bleurt Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9f144c46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-03 18:15:52.474289: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /cm/shared/apps/slurm/18.08.9/lib64/slurm:/cm/shared/apps/slurm/18.08.9/lib64\n",
      "2022-12-03 18:15:52.474330: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "Using default BLEURT-Base checkpoint for sequence maximum length 128. You can use a bigger model for better results with e.g.: datasets.load_metric('bleurt', 'bleurt-large-512').\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reading checkpoint /home/kyi/.cache/huggingface/metrics/bleurt/default/downloads/extracted/04db1fcea10999e5cc231dbfc408fcc03c8f60e13f3fac524f02511381ec77e0/bleurt-base-128.\n",
      "INFO:tensorflow:Config file found, reading.\n",
      "INFO:tensorflow:Will load checkpoint bert_custom\n",
      "INFO:tensorflow:Loads full paths and checks that files exists.\n",
      "INFO:tensorflow:... name:bert_custom\n",
      "INFO:tensorflow:... vocab_file:vocab.txt\n",
      "INFO:tensorflow:... bert_config_file:bert_config.json\n",
      "INFO:tensorflow:... do_lower_case:True\n",
      "INFO:tensorflow:... max_seq_length:128\n",
      "INFO:tensorflow:Creating BLEURT scorer.\n",
      "INFO:tensorflow:Creating WordPiece tokenizer.\n",
      "INFO:tensorflow:WordPiece tokenizer instantiated.\n",
      "INFO:tensorflow:Creating Eager Mode predictor.\n",
      "INFO:tensorflow:Loading model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-03 18:16:21.054444: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /cm/shared/apps/slurm/18.08.9/lib64/slurm:/cm/shared/apps/slurm/18.08.9/lib64\n",
      "2022-12-03 18:16:21.054541: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-12-03 18:16:21.054563: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (c0169): /proc/driver/nvidia/version does not exist\n",
      "2022-12-03 18:16:21.055087: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:BLEURT initialized.\n",
      "RNN:\n",
      "dict_values([[-1.5755281448364258, -1.3506577014923096, -1.3700361251831055, -1.4300510883331299, -1.416689395904541]])\n",
      "LSTM:\n",
      "dict_values([[-1.398155927658081, -1.4942516088485718, -1.4351022243499756, -1.5420317649841309, -1.3202416896820068]])\n",
      "GPT-2:\n",
      "dict_values([[-1.5025784969329834, -1.3701467514038086, -1.4091140031814575]])\n"
     ]
    }
   ],
   "source": [
    "#!pip install git+https://github.com/google-research/bleurt.git\n",
    "\n",
    "bleurt = load_metric(\"bleurt\", module_type=\"metric\")\n",
    "\n",
    "results = bleurt.compute(predictions=generated['RNN'].values, references=psongs[\"Lyric\"][:5].values)\n",
    "# Normally, we use the f1-score attribute\n",
    "print(\"RNN:\")\n",
    "print(results.values())\n",
    "\n",
    "results = bleurt.compute(predictions=generated['LSTM'].values, references=psongs[\"Lyric\"][:5].values)\n",
    "# Normally, we use the f1-score attribute\n",
    "print(\"LSTM:\")\n",
    "print(results.values())\n",
    "\n",
    "\n",
    "artist =  \"Lana Del Rey\"\n",
    "\n",
    "# code from Chenghui\n",
    "lyrics = pd.read_csv('lyrics-data.csv') \n",
    "lyrics=lyrics.query(\"language=='en'\")\n",
    "artists = pd.read_csv(\"artists-data.csv\")\n",
    "lyrics_df = pd.merge(lyrics,artists,left_on=\"ALink\",right_on=\"Link\")\n",
    "lyrics_df = lyrics_df[[\"Artist\",\"Genres\",\"Popularity\",\"Songs\",\"SName\",\"Lyric\"]]\n",
    "lyrics_popular=lyrics_df.query(f\"Artist=='{artist}'\")\n",
    "lyrics_popular=lyrics_popular.sort_values(['Songs','Artist'], ascending=[False,True])\n",
    "\n",
    "results = bleurt.compute(predictions=temp.values, references=lyrics_popular[\"Lyric\"][:3].values)\n",
    "# Normally, we use the f1-score attribute\n",
    "print(\"GPT-2:\")\n",
    "print(results.values())\n",
    "\n",
    "#Using first x songs as referencce"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0daca5ef",
   "metadata": {},
   "source": [
    "# Manual Evaluation\n",
    "Seems like the best way to evaluate something like lyric generation is manually evaluating it. "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
